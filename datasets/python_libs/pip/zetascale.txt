#
# This file is autogenerated by pip-compile with Python 3.12
# by the following command:
#
#    pip-compile zetascale.in
#
accelerate==1.6.0
    # via zetascale
argparse==1.4.0
    # via zetascale
beartype==0.18.5
    # via zetascale
bitsandbytes==0.42.0
    # via zetascale
certifi==2025.4.26
    # via requests
charset-normalizer==3.4.2
    # via requests
colt5-attention==0.11.1
    # via zetascale
einops==0.8.0
    # via
    #   colt5-attention
    #   einops-exts
    #   hyper-connections
    #   local-attention
    #   vector-quantize-pytorch
    #   zetascale
einops-exts==0.0.4
    # via zetascale
einx==0.3.0
    # via vector-quantize-pytorch
filelock==3.18.0
    # via
    #   huggingface-hub
    #   torch
    #   transformers
frozendict==2.4.6
    # via einx
fsspec==2025.3.2
    # via
    #   huggingface-hub
    #   torch
hf-xet==1.1.0
    # via huggingface-hub
huggingface-hub==0.31.1
    # via
    #   accelerate
    #   tokenizers
    #   transformers
hyper-connections==0.1.15
    # via local-attention
idna==3.10
    # via requests
jinja2==3.1.6
    # via torch
local-attention==1.11.1
    # via
    #   colt5-attention
    #   zetascale
loguru==0.7.3
    # via zetascale
markdown-it-py==3.0.0
    # via rich
markupsafe==3.0.2
    # via jinja2
mdurl==0.1.2
    # via markdown-it-py
mpmath==1.3.0
    # via sympy
networkx==3.4.2
    # via torch
numpy==2.2.5
    # via
    #   accelerate
    #   einx
    #   scipy
    #   torchvision
    #   transformers
packaging==25.0
    # via
    #   accelerate
    #   colt5-attention
    #   huggingface-hub
    #   transformers
pillow==11.2.1
    # via torchvision
psutil==7.0.0
    # via accelerate
pygments==2.19.1
    # via rich
pyyaml==6.0.2
    # via
    #   accelerate
    #   huggingface-hub
    #   transformers
regex==2024.11.6
    # via transformers
requests==2.32.3
    # via
    #   huggingface-hub
    #   transformers
rich==13.8.0
    # via zetascale
safetensors==0.5.3
    # via
    #   accelerate
    #   transformers
scipy==1.15.2
    # via bitsandbytes
sympy==1.14.0
    # via
    #   einx
    #   torch
tokenizers==0.19.1
    # via transformers
torch==2.7.0
    # via
    #   accelerate
    #   colt5-attention
    #   hyper-connections
    #   local-attention
    #   torchvision
    #   vector-quantize-pytorch
    #   zetascale
torchvision==0.22.0
    # via zetascale
tqdm==4.66.5
    # via
    #   huggingface-hub
    #   transformers
    #   zetascale
transformers==4.44.2
    # via zetascale
typing-extensions==4.13.2
    # via
    #   huggingface-hub
    #   torch
urllib3==2.4.0
    # via requests
vector-quantize-pytorch==1.17.1
    # via zetascale
zetascale==2.8.2
    # via -r zetascale.in

# The following packages are considered to be unsafe in a requirements file:
# setuptools
